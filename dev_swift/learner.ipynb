{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Utilities\n",
    "\n",
    "This notebook presents a design of training utilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(url: \"https://github.com/mxcl/Path.swift\", from: \"0.16.1\")\n",
      "\t\tPath\n",
      "With SwiftPM flags: []\n",
      "Working in: /tmp/tmpmar21_vs\n",
      "Fetching https://github.com/mxcl/Path.swift\n",
      "Completed resolution in 2.58s\n",
      "Cloning https://github.com/mxcl/Path.swift\n",
      "Resolving https://github.com/mxcl/Path.swift at 0.16.2\n",
      "Compile Swift Module 'Path' (9 sources)\n",
      "Compile Swift Module 'jupyterInstalledPackages' (1 sources)\n",
      "Linking ./.build/x86_64-unknown-linux/debug/libjupyterInstalledPackages.so\n",
      "Initializing Swift...\n",
      "Loading library...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install '.package(url: \"https://github.com/mxcl/Path.swift\", from: \"0.16.1\")' Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training example data structure\n",
    "\n",
    "A training example data structure consists of training data and a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// A training example, containing training data and a label. Depending on `Data` and\n",
    "/// `Label`'s implementations, the contents may represent a batch.\n",
    "public struct Example<Data: Differentiable, Label> {\n",
    "    public var data: Data\n",
    "    public var label: Label\n",
    "    \n",
    "    public init(data: Data, label: Label) {\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer (learner)\n",
    "\n",
    "A `Trainer` is responsible for initializing and training a model on a given dataset. It can be considered as a controller and an environment of model training.\n",
    "\n",
    "### Core properties\n",
    "\n",
    "`Trainer` contains three kinds of properties:\n",
    "* Core units: `model`, `dataset`, `optimizer`, `lossFunction`\n",
    "* Training states: `epochCount`, `currentEpoch`, `currentGradient`, `currentLoss`\n",
    "* Delegates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "public enum TrainerAction: Error {\n",
    "    case skipEpoch\n",
    "    case skipBatch\n",
    "    case stop\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// A model trainer, responsible for initializing and training a model on a given dataset.\n",
    "// NOTE: When TF-421 is fixed, make `Label` not constrained to `Differentiable`.\n",
    "public final class Trainer<D: Collection, Label: Differentiable,\n",
    "                           L: Differentiable & BinaryFloatingPoint,\n",
    "                           O: TensorFlow.Optimizer & AnyObject>\n",
    "    where D.Element == Example<O.Model.Input, Label>,\n",
    "          O.Scalar: Differentiable, L == L.CotangentVector\n",
    "{\n",
    "    // Common type aliases.\n",
    "    public typealias Dataset = D\n",
    "    public typealias Loss = L\n",
    "    public typealias Optimizer = O\n",
    "    public typealias Model = Optimizer.Model\n",
    "    public typealias Data = Model.Input\n",
    "    public typealias Variables = Model.AllDifferentiableVariables\n",
    "    // NOTE: When TF-421 is fixed, replace with:\n",
    "    //   public typealias LossFunction = @differentiable (Model.Output, @nondiff Label) -> Loss\n",
    "    public typealias LossFunction = @differentiable (Model.Output, Label) -> Loss\n",
    "    public typealias EventHandler = (Trainer) throws -> Void\n",
    "    \n",
    "    /// The dataset on which the model will be trained.\n",
    "    public let dataset: Dataset\n",
    "    /// The optimizer used for updating model parameters along gradient vectors.\n",
    "    public var optimizer: Optimizer\n",
    "    /// The function that computes a loss value when given a prediction and a label.\n",
    "    public var lossFunction: LossFunction\n",
    "    /// The model being trained.\n",
    "    public var model: Model\n",
    "    \n",
    "    /// The number of total epochs.\n",
    "    public private(set) var epochCount: Int = .zero\n",
    "    /// The current epoch.\n",
    "    public private(set) var currentEpoch: Int = .zero\n",
    "    /// The current gradient.\n",
    "    public private(set) var currentGradient: Model.CotangentVector = .zero\n",
    "    /// The current loss.\n",
    "    public private(set) var currentLoss: Loss = .zero\n",
    "    \n",
    "    open class Delegate {\n",
    "        open func trainingWillStart(trainer: Trainer) throws {}\n",
    "        /// The completion of model training.\n",
    "        open func trainingDidFinish(trainer: Trainer) throws {}\n",
    "        /// A closure which will be called upon the start of an epoch.\n",
    "        open func epochWillStart(trainer: Trainer) throws {}\n",
    "        /// A closure which will be called upon the completion of an epoch.\n",
    "        open func epochDidFinish(trainer: Trainer) throws {}\n",
    "        /// A closure which will be called upon the start of model validation.\n",
    "        open func validationWillStart(trainer: Trainer) throws {}\n",
    "        /// A closure which will be called upon the start of training on a batch.\n",
    "        open func batchWillStart(trainer: Trainer) throws {}\n",
    "        /// A closure which will be called upon the completion of training on a batch.\n",
    "        open func batchDidFinish(trainer: Trainer) throws {}\n",
    "        /// A closure which will be called when a new loss has been computed.\n",
    "        open func trainerDidProduceNewLoss(trainer: Trainer) throws {}\n",
    "        /// A closure which will be called when a new gradient has been computed.\n",
    "        open func trainerDidProduceNewGradient(trainer: Trainer) throws {}\n",
    "        /// A closure which will be called upon the completion of an optimizer update.\n",
    "        open func optimizerDidUpdate(trainer: Trainer) throws {}\n",
    "    }\n",
    "    public var delegates: [Delegate] = []\n",
    "    \n",
    "    /// The context used for layer applications.\n",
    "    private let context = Context(learningPhase: .training)\n",
    "\n",
    "    /// Creates a trainer.\n",
    "    ///\n",
    "    /// - Parameters:\n",
    "    ///   - dataset: The dataset which will be trained on.\n",
    "    ///   - lossFunction: The loss function.\n",
    "    ///   - optimizer: The optimizer used for updating model parameters along\n",
    "    ///     gradient vectors.\n",
    "    ///   - modelInitializer: The closure that produces an model to be trained.\n",
    "    ///\n",
    "    public init(dataset: Dataset,\n",
    "                lossFunction: @escaping LossFunction,\n",
    "                optimizer: Optimizer,\n",
    "                initializingWith modelInitializer: () -> Model) {\n",
    "        self.dataset = dataset\n",
    "        self.optimizer = optimizer\n",
    "        self.lossFunction = lossFunction\n",
    "        self.model = modelInitializer()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n",
    "\n",
    "The core method on `Trainer` is `fit(epochCount:)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Trainer {\n",
    "    /// Trains the model on the given batch.\n",
    "    ///\n",
    "    /// - Parameter batch: The batch of input data and labels to be trained on.\n",
    "    ///\n",
    "    private func train(on batch: Dataset.Element) throws {\n",
    "        // NOTE: When the \"subset of parameters\" bug is fixed, replace with:\n",
    "        //   let (loss, grad) = model.valueWithGradient { model -> Loss in\n",
    "        //      let y = model.applied(to: batch.data, in: context)\n",
    "        //      return lossFunction(y, batch.label)\n",
    "        //   }\n",
    "        let (loss, (grad, _)) = model.valueWithGradient(at: batch.label) {\n",
    "            (model, label) -> Loss in\n",
    "            let y = model.applied(to: batch.data, in: context)\n",
    "            return lossFunction(y, label)\n",
    "        }\n",
    "        // NOTE: Put this inside `valueWithGradient`'s trailing closure when differentiation\n",
    "        // supports throwing functions.\n",
    "        currentLoss = loss\n",
    "        try delegates.forEach { try $0.trainerDidProduceNewLoss(trainer: self) }\n",
    "        currentGradient = grad\n",
    "        try delegates.forEach { try $0.trainerDidProduceNewGradient(trainer: self) }\n",
    "        optimizer.update(&model.allDifferentiableVariables, along: grad)\n",
    "        try delegates.forEach { try $0.batchDidFinish(trainer: self) }\n",
    "    }\n",
    "    \n",
    "    /// Performs the `i`-th training epoch.\n",
    "    ///\n",
    "    /// - Parameter index: The epoch index.\n",
    "    private func train(atEpoch index: Int) throws {\n",
    "        currentEpoch = index\n",
    "        try delegates.forEach { try $0.epochWillStart(trainer: self) }\n",
    "        for batch in dataset {\n",
    "            try delegates.forEach { try $0.batchWillStart(trainer: self) }\n",
    "            do { try train(on: batch) }\n",
    "            catch TrainerAction.skipBatch { break }\n",
    "            try delegates.forEach { try $0.batchDidFinish(trainer: self) }\n",
    "        }\n",
    "        try delegates.forEach { try $0.epochDidFinish(trainer: self) }\n",
    "    }\n",
    "\n",
    "    /// Starts training.\n",
    "    ///\n",
    "    /// - Parameter epochCount: The number of epochs that will be run.\n",
    "    ///\n",
    "    public func train(epochCount: Int) throws {\n",
    "        self.epochCount = epochCount\n",
    "        self.currentEpoch = 0\n",
    "        do {\n",
    "            try delegates.forEach { try $0.trainingWillStart(trainer: self) }\n",
    "            for i in 0..<epochCount {\n",
    "                do { try train(atEpoch: i) }\n",
    "                catch TrainerAction.skipEpoch { break }\n",
    "            }\n",
    "            try delegates.forEach { try $0.trainingDidFinish(trainer: self) }\n",
    "        } catch TrainerAction.stop { return }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the short term, we call it `Learner` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "public typealias Learner = Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Trainer {\n",
    "    public class Recorder: Delegate {\n",
    "        public var losses: [Loss] = []\n",
    "        public var learningRates: [Optimizer.Scalar] = []\n",
    "\n",
    "        public override func trainingWillStart(trainer: Trainer) throws {\n",
    "            losses = []\n",
    "            learningRates = []\n",
    "        }\n",
    "\n",
    "        public override func optimizerDidUpdate(trainer: Trainer) throws {\n",
    "            losses.append(trainer.currentLoss)\n",
    "            learningRates.append(trainer.optimizer.learningRate)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    public class ParameterScheduler<Parameter>: Delegate {\n",
    "        public var keyPath: WritableKeyPath<Model, Parameter>\n",
    "        public var schedule: (Optimizer.Scalar) -> Parameter\n",
    "\n",
    "        public init(keyPath: WritableKeyPath<Model, Parameter>,\n",
    "             schedule: @escaping (Optimizer.Scalar) -> Parameter) {\n",
    "            self.keyPath = keyPath\n",
    "            self.schedule = schedule\n",
    "        }\n",
    "        \n",
    "        public override func batchWillStart(trainer: Trainer) throws {\n",
    "            let ratio = Optimizer.Scalar(trainer.currentEpoch)\n",
    "                / Optimizer.Scalar(trainer.epochCount)\n",
    "            trainer.model[keyPath: keyPath] = schedule(ratio)\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let outputCount = 10\n",
    "\n",
    "struct MyModel: Layer {\n",
    "    var layer1 = Dense<Float>(inputSize: 2, outputSize: 4, activation: relu)\n",
    "    var layer2 = Dense<Float>(inputSize: 4, outputSize: 2, activation: relu)\n",
    "    \n",
    "    @differentiable\n",
    "    func applied(to input: Tensor<Float>, in context: Context) -> Tensor<Float> {\n",
    "        return input.sequenced(in: context, through: layer1, layer2)\n",
    "    }\n",
    "}\n",
    "\n",
    "// let trainer = Trainer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
